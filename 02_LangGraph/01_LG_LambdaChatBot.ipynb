{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8c451ffd-a18b-4412-85fa-85186824dd03",
      "metadata": {
        "id": "8c451ffd-a18b-4412-85fa-85186824dd03"
      },
      "source": [
        "# LangGraph Chatbot with AWS Lambda tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3363afa1",
      "metadata": {
        "id": "3363afa1"
      },
      "source": [
        "This code block installs the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d779beb7",
      "metadata": {
        "id": "d779beb7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --quiet -U langchain_openai langchain_core langgraph langgraph-prebuilt boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe916ed",
      "metadata": {
        "id": "dfe916ed"
      },
      "source": [
        "This code block imports the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0ca76cb3",
      "metadata": {
        "id": "0ca76cb3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-871ef734c6ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToolMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import json\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2857bf8",
      "metadata": {
        "id": "b2857bf8"
      },
      "source": [
        "This code block sets up the environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060d2187",
      "metadata": {
        "id": "060d2187"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Setup environment\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv('AWS_DEFAULT_REGION')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"tutorial\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b8fcdd",
      "metadata": {
        "id": "e8b8fcdd"
      },
      "source": [
        "# Define AWS Lambda tools\n",
        "\n",
        "This code block initializes the AWS Lambda client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92911f14",
      "metadata": {
        "id": "92911f14"
      },
      "outputs": [],
      "source": [
        "lambda_client = boto3.client('lambda', region_name='us-east-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cead526c",
      "metadata": {
        "id": "cead526c"
      },
      "source": [
        "This code block defines a tool to fetch ticket details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82502c06",
      "metadata": {
        "id": "82502c06"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_ticket_details(ticket_id: str) -> dict:\n",
        "    \"\"\"Fetch ticket details for the provided ticket ID.\"\"\"\n",
        "    payload = {\"ticket_id\": ticket_id}\n",
        "    response = lambda_client.invoke(\n",
        "        FunctionName=\"get_ticket_details\",\n",
        "        InvocationType=\"RequestResponse\",\n",
        "        Payload=json.dumps(payload),\n",
        "    )\n",
        "    return json.load(response[\"Payload\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af20c0c",
      "metadata": {
        "id": "4af20c0c"
      },
      "source": [
        "This code block defines a tool to get failure details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2696717e",
      "metadata": {
        "id": "2696717e"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_failure_details(failure_code: str) -> dict:\n",
        "    \"\"\"Get detailed information about a failure using the failure code.\"\"\"\n",
        "    payload = {\"failure_code\": failure_code}\n",
        "    response = lambda_client.invoke(\n",
        "        FunctionName=\"get_failure_details\",\n",
        "        InvocationType=\"RequestResponse\",\n",
        "        Payload=json.dumps(payload),\n",
        "    )\n",
        "    return json.load(response[\"Payload\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf59deb",
      "metadata": {
        "id": "2bf59deb"
      },
      "source": [
        "This code block defines a tool to get resolution steps for a failure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a86ccb",
      "metadata": {
        "id": "14a86ccb"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def fix_failure_steps(failure_code: str) -> dict:\n",
        "    \"\"\"Get resolution steps for a given failure code.\"\"\"\n",
        "    payload = {\"failure_code\": failure_code}\n",
        "    response = lambda_client.invoke(\n",
        "        FunctionName=\"fix_failure_steps\",\n",
        "        InvocationType=\"RequestResponse\",\n",
        "        Payload=json.dumps(payload),\n",
        "    )\n",
        "    return json.load(response[\"Payload\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdfc1732",
      "metadata": {
        "id": "fdfc1732"
      },
      "source": [
        "This code block defines a tool to search and explain failure details using Amazon Bedrock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da58faa",
      "metadata": {
        "id": "1da58faa"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_failure_bedrock(failure_info: dict) -> dict:\n",
        "    \"\"\"Search and explain failure details using Amazon Bedrock (Mistral).\"\"\"\n",
        "    failure_code = failure_info.get(\"failure_code\", \"\")\n",
        "    description = failure_info.get(\"description\", \"\")\n",
        "    query = f\"Explain the failure '{description}' and its cause\"\n",
        "\n",
        "    payload = {\"query\": query}\n",
        "    response = lambda_client.invoke(\n",
        "        FunctionName=\"search_failure_bedrock\",\n",
        "        InvocationType=\"RequestResponse\",\n",
        "        Payload=json.dumps(payload),\n",
        "    )\n",
        "    return json.load(response[\"Payload\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca2e280",
      "metadata": {
        "id": "fca2e280"
      },
      "source": [
        "This code block defines the list of tools to be used by the chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e832a7",
      "metadata": {
        "id": "d5e832a7"
      },
      "outputs": [],
      "source": [
        "tools = [get_ticket_details, get_failure_details, fix_failure_steps, search_failure_bedrock]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dkViTe4RL6je",
      "metadata": {
        "id": "dkViTe4RL6je"
      },
      "source": [
        "# Define LangGraph state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99f6e605",
      "metadata": {
        "id": "99f6e605"
      },
      "source": [
        "This code block defines the LangGraph state and the chatbot node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07fcd13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c07fcd13",
        "outputId": "a41494a7-761b-4488-fec9-2cf8af89aa3b"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"]) ]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iaB3ngeML9XO",
      "metadata": {
        "id": "iaB3ngeML9XO"
      },
      "source": [
        "# Define tool execution node"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5911da4b",
      "metadata": {
        "id": "5911da4b"
      },
      "source": [
        "This code block defines the tool execution node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18363b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e18363b1",
        "outputId": "85810c42-2a53-424d-df34-f9d19d893d3c"
      },
      "outputs": [],
      "source": [
        "class BasicToolNode:\n",
        "    def __init__(self, tools: list):\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        messages = inputs.get(\"messages\", [])\n",
        "        if not messages:\n",
        "            raise ValueError(\"No messages found in input\")\n",
        "        message = messages[-1]\n",
        "        outputs = []\n",
        "\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            args = tool_call.get(\"args\", {})\n",
        "\n",
        "            if tool_name == \"search_failure_bedrock\" and not args:\n",
        "                failure_code, description = None, None\n",
        "                for msg in messages:\n",
        "                    if isinstance(msg, ToolMessage) and msg.name == \"get_ticket_details\":\n",
        "                        content = json.loads(msg.content)\n",
        "                        failure_code = content.get(\"failureCode\")\n",
        "                        description = content.get(\"description\")\n",
        "                args = {\"failure_info\": {\"failure_code\": failure_code or \"UNKNOWN\", \"description\": description or \"No description available.\"}}\n",
        "\n",
        "            print(f\"[INFO] Tool Invoked: {tool_name}\")\n",
        "            result = self.tools_by_name[tool_name].invoke(args)\n",
        "            outputs.append(ToolMessage(content=json.dumps(result), name=tool_name, tool_call_id=tool_call[\"id\"]))\n",
        "\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O23GC7NVL_36",
      "metadata": {
        "id": "O23GC7NVL_36"
      },
      "source": [
        "# Routing logic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c3a0f20",
      "metadata": {
        "id": "9c3a0f20"
      },
      "source": [
        "This code block defines the routing logic for the LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4aa1cbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "e4aa1cbe",
        "outputId": "9117038b-0c2e-4d01-8f9f-cd2d53f40c2c"
      },
      "outputs": [],
      "source": [
        "def route_tools(state: State):\n",
        "    ai_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
        "    if ai_message and hasattr(ai_message, \"tool_calls\") and ai_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "graph_builder.add_conditional_edges(\"chatbot\", route_tools, {\"tools\": \"tools\", END: END})\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# Optional visualization\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7918c1b8",
      "metadata": {
        "id": "7918c1b8"
      },
      "source": [
        "This code block contains the interaction loop to ask questions to the chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d81d82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10d81d82",
        "outputId": "59a67855-0b87-496f-c6ff-62f1cae118a5"
      },
      "outputs": [],
      "source": [
        "# Interaction loop\n",
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            if \"messages\" in value and value[\"messages\"]:\n",
        "                print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        user_input = \"Hello\"\n",
        "        print(\"User:\", user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e1e687",
      "metadata": {
        "id": "80e1e687"
      },
      "source": [
        "These are example prompts to use with the chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98800024",
      "metadata": {
        "id": "98800024"
      },
      "outputs": [],
      "source": [
        "# prompt1: Fetch the details for ticket ID TICKET12345, extract the failure code, use it to retrieve the failure details, and then obtain the appropriate fix or resolution steps for the identified failure.\n",
        "\n",
        "# prompt2: Fetch the details for ticket ID TICKET12345, extract the failure code, use it to retrieve the failure details, finally search and explain the failure in detail using GenAI."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
